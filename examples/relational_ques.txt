I am working with the data is loaded into the `stack_200` database (connection string: `postgresql+psycopg2://mlflow:mlflow@postgres:5432/stack_200`).

I want to define a predictive task on this relational database using the Relational Deep Learning agents.

**Task Definition:**
- **Target Entity:** `Posts` (specifically questions).
- **Prediction Goal:** Predict if a newly posted question will receive any Upvotes (`VoteTypeId = 2` in `Votes` table) within the next 1 months (horizon = 1 months).
- **Task Type:** Binary Classification (Label 1 if upvotes > 0, else 0).

**Input & Graph Construction:**
- Leverage the full relational schema (Users, Posts, Votes, Comments, Badges, etc.) as a Heterogeneous Graph.
- **Node Features:**
    - `Posts`: Use `Title` and `Body` (Text features), `CreationDate` (Timestamp).
    - `Users`: Use `Reputation` (Numerical), `DisplayName` (Text).
- **Edges:** Automatically infer from Foreign Keys.

**Temporal Splitting:**
- Use `CreationDate` in the `Posts` table to perform time-based splitting (Train/Val/Test) to prevent data leakage.


------------------------------------------
Here are my specifications to proceed with the Relational Deep Learning pipeline:
Output Schema: Represent the prediction label as an Integer (0 or 1). 
Context: This corresponds to the target column $y$ in the Training Table defined by the Temporal Task Supervisor.

Input Schema & Graph Construction: 
Do not manually define the schema. Instead, please activate the Relational Graph Architect Agent.
Ensure Time is treated as a first-class citizen by extracting timestamps from the Posts table (CreationDate) to assign $t_v$ to nodes.
Model Solutions:
I request 1 optimized Relational GNN solution (e.g., Heterogeneous Graph Transformer or R-GCN).
Please assign the Relational GNN Specialist to handle the training loop using Time-Consistent Neighbor Sampling to prevent temporal leakage. 
Please proceed.